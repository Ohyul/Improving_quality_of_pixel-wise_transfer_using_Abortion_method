{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "from criteria.lpips.utils import normalize_activation\n",
    "\n",
    "\n",
    "def get_network(net_type: str):\n",
    "    if net_type == 'alex':\n",
    "        return AlexNet()\n",
    "    elif net_type == 'squeeze':\n",
    "        return SqueezeNet()\n",
    "    elif net_type == 'vgg':\n",
    "        return VGG16()\n",
    "    else:\n",
    "        raise NotImplementedError('choose net_type from [alex, squeeze, vgg].')\n",
    "\n",
    "\n",
    "class LinLayers(nn.ModuleList):\n",
    "    def __init__(self, n_channels_list: Sequence[int]):\n",
    "        super(LinLayers, self).__init__([\n",
    "            nn.Sequential(\n",
    "                nn.Identity(),\n",
    "                nn.Conv2d(nc, 1, 1, 1, 0, bias=False)\n",
    "            ) for nc in n_channels_list\n",
    "        ])\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "\n",
    "        # register buffer\n",
    "        self.register_buffer(\n",
    "            'mean', torch.Tensor([-.030, -.088, -.188])[None, :, None, None])\n",
    "        self.register_buffer(\n",
    "            'std', torch.Tensor([.458, .448, .450])[None, :, None, None])\n",
    "\n",
    "    def set_requires_grad(self, state: bool):\n",
    "        for param in chain(self.parameters(), self.buffers()):\n",
    "            param.requires_grad = state\n",
    "\n",
    "    def z_score(self, x: torch.Tensor):\n",
    "        return (x - self.mean) / self.std\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.z_score(x)\n",
    "\n",
    "        output = []\n",
    "        for i, (_, layer) in enumerate(self.layers._modules.items(), 1):\n",
    "            x = layer(x)\n",
    "            if i in self.target_layers:\n",
    "                output.append(normalize_activation(x))\n",
    "            if len(output) == len(self.target_layers):\n",
    "                break\n",
    "        return output\n",
    "\n",
    "\n",
    "class SqueezeNet(BaseNet):\n",
    "    def __init__(self):\n",
    "        super(SqueezeNet, self).__init__()\n",
    "\n",
    "        self.layers = models.squeezenet1_1(True).features\n",
    "        self.target_layers = [2, 5, 8, 10, 11, 12, 13]\n",
    "        self.n_channels_list = [64, 128, 256, 384, 384, 512, 512]\n",
    "\n",
    "        self.set_requires_grad(False)\n",
    "\n",
    "\n",
    "class AlexNet(BaseNet):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.layers = models.alexnet(True).features\n",
    "        self.target_layers = [2, 5, 8, 10, 12]\n",
    "        self.n_channels_list = [64, 192, 384, 256, 256]\n",
    "\n",
    "        self.set_requires_grad(False)\n",
    "\n",
    "\n",
    "class VGG16(BaseNet):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        self.layers = models.vgg16(True).features\n",
    "        self.target_layers = [4, 9, 16, 23, 30]\n",
    "        self.n_channels_list = [64, 128, 256, 512, 512]\n",
    "\n",
    "        self.set_requires_grad(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
