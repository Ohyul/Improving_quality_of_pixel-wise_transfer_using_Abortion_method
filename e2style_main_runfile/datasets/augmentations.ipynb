{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ToOneHot(object):\n",
    "\t\"\"\" Convert the input PIL image to a one-hot torch tensor \"\"\"\n",
    "\tdef __init__(self, n_classes=None):\n",
    "\t\tself.n_classes = n_classes\n",
    "\n",
    "\tdef onehot_initialization(self, a):\n",
    "\t\tif self.n_classes is None:\n",
    "\t\t\tself.n_classes = len(np.unique(a))\n",
    "\t\tout = np.zeros(a.shape + (self.n_classes, ), dtype=int)\n",
    "\t\tout[self.__all_idx(a, axis=2)] = 1\n",
    "\t\treturn out\n",
    "\n",
    "\tdef __all_idx(self, idx, axis):\n",
    "\t\tgrid = np.ogrid[tuple(map(slice, idx.shape))]\n",
    "\t\tgrid.insert(axis, idx)\n",
    "\t\treturn tuple(grid)\n",
    "\n",
    "\tdef __call__(self, img):\n",
    "\t\timg = np.array(img)\n",
    "\t\tone_hot = self.onehot_initialization(img)\n",
    "\t\treturn one_hot\n",
    "\n",
    "\n",
    "class BilinearResize(object):\n",
    "\tdef __init__(self, factors=[1, 2, 4, 8, 16, 32]):\n",
    "\t\tself.factors = factors\n",
    "\n",
    "\tdef __call__(self, image):\n",
    "\t\tfactor = np.random.choice(self.factors, size=1)[0]\n",
    "\t\tD = BicubicDownSample(factor=factor, cuda=False)\n",
    "\t\timg_tensor = transforms.ToTensor()(image).unsqueeze(0)\n",
    "\t\timg_tensor_lr = D(img_tensor)[0].clamp(0, 1)\n",
    "\t\timg_low_res = transforms.ToPILImage()(img_tensor_lr)\n",
    "\t\treturn img_low_res\n",
    "\n",
    "\n",
    "class BicubicDownSample(nn.Module):\n",
    "\tdef bicubic_kernel(self, x, a=-0.50):\n",
    "\t\t\"\"\"\n",
    "\t\tThis equation is exactly copied from the website below:\n",
    "\t\thttps://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic\n",
    "\t\t\"\"\"\n",
    "\t\tabs_x = torch.abs(x)\n",
    "\t\tif abs_x <= 1.:\n",
    "\t\t\treturn (a + 2.) * torch.pow(abs_x, 3.) - (a + 3.) * torch.pow(abs_x, 2.) + 1\n",
    "\t\telif 1. < abs_x < 2.:\n",
    "\t\t\treturn a * torch.pow(abs_x, 3) - 5. * a * torch.pow(abs_x, 2.) + 8. * a * abs_x - 4. * a\n",
    "\t\telse:\n",
    "\t\t\treturn 0.0\n",
    "\n",
    "\tdef __init__(self, factor=4, cuda=True, padding='reflect'):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.factor = factor\n",
    "\t\tsize = factor * 4\n",
    "\t\tk = torch.tensor([self.bicubic_kernel((i - torch.floor(torch.tensor(size / 2)) + 0.5) / factor)\n",
    "\t\t\t\t\t\t  for i in range(size)], dtype=torch.float32)\n",
    "\t\tk = k / torch.sum(k)\n",
    "\t\tk1 = torch.reshape(k, shape=(1, 1, size, 1))\n",
    "\t\tself.k1 = torch.cat([k1, k1, k1], dim=0)\n",
    "\t\tk2 = torch.reshape(k, shape=(1, 1, 1, size))\n",
    "\t\tself.k2 = torch.cat([k2, k2, k2], dim=0)\n",
    "\t\tself.cuda = '.cuda' if cuda else ''\n",
    "\t\tself.padding = padding\n",
    "\t\tfor param in self.parameters():\n",
    "\t\t\tparam.requires_grad = False\n",
    "\n",
    "\tdef forward(self, x, nhwc=False, clip_round=False, byte_output=False):\n",
    "\t\tfilter_height = self.factor * 4\n",
    "\t\tfilter_width = self.factor * 4\n",
    "\t\tstride = self.factor\n",
    "\n",
    "\t\tpad_along_height = max(filter_height - stride, 0)\n",
    "\t\tpad_along_width = max(filter_width - stride, 0)\n",
    "\t\tfilters1 = self.k1.type('torch{}.FloatTensor'.format(self.cuda))\n",
    "\t\tfilters2 = self.k2.type('torch{}.FloatTensor'.format(self.cuda))\n",
    "\n",
    "\t\t# compute actual padding values for each side\n",
    "\t\tpad_top = pad_along_height // 2\n",
    "\t\tpad_bottom = pad_along_height - pad_top\n",
    "\t\tpad_left = pad_along_width // 2\n",
    "\t\tpad_right = pad_along_width - pad_left\n",
    "\n",
    "\t\t# apply mirror padding\n",
    "\t\tif nhwc:\n",
    "\t\t\tx = torch.transpose(torch.transpose(x, 2, 3), 1, 2)   # NHWC to NCHW\n",
    "\n",
    "\t\t# downscaling performed by 1-d convolution\n",
    "\t\tx = F.pad(x, (0, 0, pad_top, pad_bottom), self.padding)\n",
    "\t\tx = F.conv2d(input=x, weight=filters1, stride=(stride, 1), groups=3)\n",
    "\t\tif clip_round:\n",
    "\t\t\tx = torch.clamp(torch.round(x), 0.0, 255.)\n",
    "\n",
    "\t\tx = F.pad(x, (pad_left, pad_right, 0, 0), self.padding)\n",
    "\t\tx = F.conv2d(input=x, weight=filters2, stride=(1, stride), groups=3)\n",
    "\t\tif clip_round:\n",
    "\t\t\tx = torch.clamp(torch.round(x), 0.0, 255.)\n",
    "\n",
    "\t\tif nhwc:\n",
    "\t\t\tx = torch.transpose(torch.transpose(x, 1, 3), 1, 2)\n",
    "\t\tif byte_output:\n",
    "\t\t\treturn x.type('torch.ByteTensor'.format(self.cuda))\n",
    "\t\telse:\n",
    "\t\t\treturn x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
